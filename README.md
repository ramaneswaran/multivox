# MultiVox

MultiVox is a benchmark to assess how well omni-modal language models can integrate audio and visual cues to give a contextual repsonse

### Example baseline

We provide scripts to run Qwen 2.5 Omni using vLLM here

```python
python3 src/baseline_qwen.py
```

### Evaluation

We use GPT 4.1-mini to run evaluation. You can use the following script to run evaluation

```python
python3 src/evaluate.py
```